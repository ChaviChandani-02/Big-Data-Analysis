# Big-Data-Analysis

COMPANY- CODTECH IT SOLUTIONS

NAME- CHAVI CHANDANI

INTERN ID- CT04DA482

DOMAIN- DATA ANALYTICS

DURATION- 4 WEEKS

MENTOR- NEELA SANTOSH


# NETFLIX VIEWERSHIP ASIS USING PYSPARKNALY
# OVERVIEW

The internship task revolves around Big Data Analysis using Apache Spark, with a specific focus on analyzing Netflix viewership data. The goal of the project is to explore Netflix's content trends, including the most popular shows, categories, countries, and viewership patterns. This analysis helps uncover valuable insights into consumer behavior and content performance, which can directly inform marketing strategies, content creation, and regional content expansion. By utilizing Spark, the project handles large-scale data efficiently, which is crucial when dealing with vast amounts of streaming data like those generated by Netflix.

Apache Spark was chosen as the primary tool for data processing due to its ability to scale across distributed systems, allowing for the handling of large datasets in a fast and efficient manner. Alongside Spark, other Python libraries such as Pandas, Matplotlib, and Seaborn were used to preprocess, analyze, and visualize the data.

# Tools and Technologies Used:
Apache Spark (PySpark):

-PySpark is the Python API for Apache Spark, a powerful, open-source, distributed computing framework designed to handle large-scale data processing. PySpark allows for distributed data processing and provides high performance through parallel computation.
-Spark SQL is used to run SQL queries on large datasets efficiently, while PySpark DataFrames provide easy manipulation and transformation of structured data.

Google Colab:

-Google Colab is a cloud-based platform that allows you to write and execute Python code in an interactive notebook format. It provides free access to hardware accelerators like GPUs and TPUs, making it ideal for Big Data tasks when working with PySpark. In this task, Google Colab is used to run the PySpark code and perform data analysis on the large Netflix dataset.

CSV (Comma-Separated Values):

-CSV files are used as the data format for storing and exchanging large datasets. The Netflix dataset is loaded from a CSV file into a PySpark DataFrame using spark.read.csv() method.

Matplotlib & Seaborn:

-These Python libraries are used for data visualization. They allow for generating insightful plots like bar charts, line plots, and heatmaps. In this task, they are used to visualize the key trends and insights derived from the large Netflix dataset, such as the top 10 most frequent shows, popular categories, country trends, and unique titles.

Python:

-The programming language used for the task. Python is widely used in data science and machine learning, and when combined with PySpark, it can handle Big Data processing tasks with ease.
